---
layout: post
title:  "Cuda 1 - GPU Programming & Memory Model"
date:   2016-4-3 17:00:00
tags: [cuda, programming, memory, model]
categories: Programming
---

> UDACITY教程 [Intro to Parallel Programming][link] 

[link]: https://www.udacity.com/wiki/cs344

### 1. host(cpu): h_in;  device(gpu): d_in

### 2. square\<\<\<1, 64\>\>\> (d_out, d_in)
尖括号内blocks, threads(512 or 1024 at most)

\<\<\<dim3(bx,by,bz), dim3(tx,ty,tz),shared_mem\>\>\>

### 3. Problem 1:
Convert color image to gray:
[my-solution](https://github.com/wykvictor/cs344-udacity/commit/c9205c5515dcb37426086742ef52adca093d7228)

### 4. Memory patterns: 5 kinds
![gpu-communication-pattern](http://7xno5y.com1.z0.glb.clouddn.com/gpu-communication-pattern.png)

map, gather, scatter

stencil patterns: data reuse, 特定位置的邻居获取data(Note: 所有的index都要计算, i%2不算)

transpose-reorder data elements in array: array of structures(AOS), structure of arrays(SOA)

L: out[i + j\*128] = in[j + i\*128] ==> transpose operation

### 5. Hardware <--> Blocks
![gpu-sm-block](http://7xno5y.com1.z0.glb.clouddn.com/gpu-sm-block.png)

An SM could run more than one block;

Threads in different blocks should not cooperate(even in a same SM)

### 6. Memory Model
Local, Shared, Global Memory

![gpu-memory-model](http://7xno5y.com1.z0.glb.clouddn.com/gpu-memory-model.png)

This is shared memory: **\_\_shared\_\_ float sh_arr[128]**

### 7. GPU hardware build-in: atomic operations
atomicAdd()... (功能上与\_\_syncthreads()相近，但更快)

### 8. Thread divergence - efficiency down
Avoid these in kernel: if/else; for-loop with different iters/thread

### 9. Problem 2:
Image blur:
[my-solution](https://github.com/wykvictor/cs344-udacity/blob/master/Problem%20Sets/Problem%20Set%202/student_func.cu)
